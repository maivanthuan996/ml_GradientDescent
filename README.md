# Training Two Parameter Mini-Batch Gradient DecentÂ¶

In this study, practice training how to use Mini-Batch Descent to train models in the PyTorch framework.

- Make some Data
- Create the Model and Cost Function (Total Loss)
- Train the Model: Batch Gradient Descent
- Train the Model: Stochastic Gradient Descent with Dataset DataLoader
- Train the Model: Mini Batch Gradient Decent: Batch size equals 5
- Train the Model: Mini Batch Gradient Decent: Batch size equals 10



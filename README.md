<details>
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#introduction">Introduction</a>
    </li>
    <li><a href="#Make some Data">Make some Data</a></li>
    <li><a href="#Create the Model and Cost Function (Total Loss)">Create the Model and Cost Function (Total Loss)</a></li>
    <li><a href="#Train the Model: Batch Gradient Descent">Train the Model: Batch Gradient Descent</a></li>
    <li><a href="#Train the Model: Stochastic Gradient Descent with Dataset DataLoader">Train the Model: Stochastic Gradient Descent with Dataset DataLoader</a></li>
    <li><a href="#Train the Model: Mini Batch Gradient Decent: Batch size equals 5">Train the Model: Mini Batch Gradient Decent: Batch size equals 5</a></li>
    <li><a href="#Train the Model: Mini Batch Gradient Decent: Batch size equals 10">Train the Model: Mini Batch Gradient Decent: Batch size equals 10</a></li>
    <li><a href="#examining-results">Examining results</a></li>
    <li><a href="#summary">Summary</a></li>

  </ol>
</details>

# Training Two Parameter Mini-Batch Gradient DecentÂ¶

### Introduction
In this study, practice training how to use Mini-Batch Descent to train models in the PyTorch framework.

### Make some Data

### Create the Model and Cost Function (Total Loss)

### Train the Model: Batch Gradient Descent

### Train the Model: Stochastic Gradient Descent with Dataset DataLoader

### Train the Model: Mini Batch Gradient Decent: Batch size equals 5

### Train the Model: Mini Batch Gradient Decent: Batch size equals 10

### Examining-results

### Summary

